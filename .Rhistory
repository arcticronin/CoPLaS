cat("\014")
rm(list = ls())
library(ISLR)
data <- College
? ISLR:: College
data <- data[, -1]
names(data)
dim(data)
attach(data)
cat("\014")
rm(list = ls())
library(ISLR)
data <- College
? ISLR:: College
library(ISLR)
data <- College
? ISLR:: College
data <- data[, -1]
names(data)
dim(data)
attach(data)
## (a)
set.seed(1)
train <- sample(c(TRUE, FALSE), nrow(data), replace = TRUE, prob = c(0.7, 0.3))
attach(data)
## (a)
set.seed(1)
cat("\014")
rm(list = ls())
library(ISLR)
data <- College
? ISLR:: College
data <- data[, -1]
names(data)
dim(data)
attach(data)
## (a)
set.seed(1)
train <- sample(c(TRUE, FALSE), nrow(data), replace = TRUE, prob = c(0.7, 0.3))
## (b) LS Regression
? lm
lm.fit <- lm(Apps ~ ., data = data, subset = train)
lm.pred <- predict(lm.fit, data[!train,])
lm.mse <- mean((lm.pred-Apps[!train])^2)
## (c) Ridge Regression
? model.matrix
x <- model.matrix (Apps ~ ., data)[, -1]
y <- Apps
library(glmnet)
? glmnet
## Before fitting the Ridge regression, analyse the variability of the data.
str(data)
library(pracma)
heatmap(cov(data[,-c(1:2)]), Colv = NA, Rowv = NA)
apply(data[, -1], 2, sd)
grid <- 10^seq(10, -2, length = 100)
length(grid)
...
ridge.mod <- glmnet( x, y, alpha = 0, lambda = grid)
library(glmnet)
install.packages("glmnet")
ridge.mod <- glmnet( x, y, alpha = 0, lambda = grid)
##install.packages("glmnet")
library(glmnet)
##install.packages("glmnet")
library(glmnet)
install.packages("glmnet")
library(glmnet)
library(glmnet)
install.packages("glmnet")
install.packages("glmnet")
install.packages("glmnet")
install.packages("Matrix")
install.package("foreach")
install.packages("foreach")
install.packages("shape")
install.packages("glmnet")
install.packages("glmnet")
library(glmnet)
? glmnet
## Before fitting the Ridge regression, analyse the variability of the data.
str(data)
library(pracma)
heatmap(cov(data[,-c(1:2)]), Colv = NA, Rowv = NA)
apply(data[, -1], 2, sd)
grid <- 10^seq(10, -2, length = 100)
length(grid)
ridge.mod <- glmnet( x, y, alpha = 0, lambda = grid)
## Before fitting the Ridge regression, analyse the variability of the data.
str(data)
library(pracma)
heatmap(cov(data[,-c(1:2)]), Colv = NA, Rowv = NA)
apply(data[, -1], 2, sd)
grid <- 10^seq(10, -2, length = 100)
length(grid)
ridge.mod <- glmnet( x, y, alpha = 0, lambda = grid)
cv.out <- cv.glmnet(x[train,], y[train,], alpha = 0)
cv.out <- cv.glmnet(x[train,], y[train,], alpha = 0)
x <- model.matrix (Apps ~ ., data)[, -1]
y <- Apps
install.packages("Matrix")
grid <- 10^seq(10, -2, length = 100)
length(grid)
ridge.mod <- glmnet( x, y, alpha = 0, lambda = grid)
## Which is the behaviour of the coefficient estimates when lambda increases?
coef.ridgemodel
ridge.mod <- glmnet( x, y, alpha = 0, lambda = grid)
## Which is the behaviour of the coefficient estimates when lambda increases?
coef.ridgemodel
## Which is the behaviour of the coefficient estimates when lambda increases?
coef.ridge.mod
ridge.pred <- predict(ridge.mod, newx = x[!train,])
ridge.pred <- predict(ridge.mod, newx = x[!train,], s = best.lambda.ridge)
cv.out <- cv.glmnet(x[train,], y[train,], alpha = 0)
cv.out <- cv.glmnet(x[train,], y[train,], alpha = 0)
best.lambda.ridge <- cv.out$lambda.min
best.lambda.ridge
log(best.lambda.ridge)
ridge.pred <- predict(ridge.mod, newx = x[!train,], s = best.lambda.ridge)
cat("\014")
rm(list = ls())
library(ISLR)
data <- College
? ISLR:: College
data <- data[, -1]
names(data)
dim(data)
attach(data)
## (a)
set.seed(1)
train <- sample(c(TRUE, FALSE), nrow(data), replace = TRUE, prob = c(0.7, 0.3))
## (b) LS Regression
? lm
lm.fit <- lm(Apps ~ ., data = data, subset = train)
lm.pred <- predict(lm.fit, data[!train,])
lm.mse <- mean((lm.pred-Apps[!train])^2)
## (c) Ridge Regression
? model.matrix
x <- model.matrix (Apps ~ ., data)[, -1]
y <- Apps
##install.packages("Matrix")
##install.packages("foreach")
##install.packages("shape")
##install.packages("glmnet")
library(glmnet)
? glmnet
## Before fitting the Ridge regression, analyse the variability of the data.
str(data)
library(pracma)
heatmap(cov(data[,-c(1:2)]), Colv = NA, Rowv = NA)
apply(data[, -1], 2, sd)
grid <- 10^seq(10, -2, length = 100)
length(grid)
ridge.mod <- glmnet( x, y, alpha = 0, lambda = grid)
## Which is the behaviour of the coefficient estimates when lambda increases?
coef.ridge.mod =
## How to choose the tuning parameter?
? cv.glmnet
cv.out <- cv.glmnet(x[train,], y[train,], alpha = 0)
cv.out <- cv.glmnet(x[train,-1], y[train,], alpha = 0)
cv.out <- cv.glmnet(x[train], y[train,], alpha = 0)
coef.ridge.mod = ridge.mod
coef.ridge.mod = ridge.mod$lambda
lasso.mod <- glmnet(x[train,],y[train,],alpha = grid)
dim(coef(lasso.mod))
lasso.mod <- glmnet(x[train,],y[train,],alpha = grid)
lasso.mod <- glmnet(x[train,], y[train,], alpha = grid, nlambda = 100)
lasso.mod <- glmnet(x[train,], y[train,], alpha = 1, lambda = grid, nlambda = 100)
install.packages("prioritylasso")
"ciap" + " + 10"
paste("1o" "20")
paste("1o", "20")
library(glmnet)
install.packages("glmnet")
library(survival)
library(glmnet)
step2 <- read.csv("step2.csv")
# Viewing the first few rows of the dataframe
head(my_data)
cox_lasso_model_with_offset <- function(df) {
# Ensure 'time' and 'event' are in the right format
y <- with(df, Surv(time, event))
# Prepare the matrix of predictors (excluding the offset)
x <- as.matrix(df[, setdiff(names(df), c("time", "event", "offset"))])
# Extract the offset
offset_values <- df$offset
# Fit Cox model with Lasso using cross-validation, including the offset
fit <- cv.glmnet(x, y, family="cox", alpha=1, offset=offset_values) # alpha=1 for Lasso
# Return the best fit and lambda value
best_lambda <- fit$lambda.min
best_fit <- glmnet(x, y, family="cox", alpha=1, lambda=best_lambda, offset=offset_values)
return(list(coef=coef(best_fit), lambda=best_lambda, fit=best_fit))
}
result <- cox_lasso_model_with_offset(step2)
library(survival)
library(glmnet)
setwd("/home/ronin/Dev/notebooks/thesis_notebook/")
step2 <- read.csv("step2.csv")
library(survival)
library(glmnet)
setwd("/home/ronin/Dev/notebooks/thesis_notebook/")
step2 <- read.csv("step2.csv")
# Viewing the first few rows of the dataframe
head(my_data)
# Viewing the first few rows of the dataframe
head(step2)
cox_lasso_model_with_offset <- function(df) {
# Ensure 'time' and 'event' are in the right format
y <- with(df, Surv(time, event))
# Prepare the matrix of predictors (excluding the offset)
x <- as.matrix(df[, setdiff(names(df), c("time", "event", "offset"))])
# Extract the offset
offset_values <- df$offset
# Fit Cox model with Lasso using cross-validation, including the offset
fit <- cv.glmnet(x, y, family="cox", alpha=1, offset=offset_values) # alpha=1 for Lasso
# Return the best fit and lambda value
best_lambda <- fit$lambda.min
best_fit <- glmnet(x, y, family="cox", alpha=1, lambda=best_lambda, offset=offset_values)
return(list(coef=coef(best_fit), lambda=best_lambda, fit=best_fit))
}
result <- cox_lasso_model_with_offset(step2)
result$coef
mat1 <- as.matrix(result$coef)
View(mat1)
View(mat1)
library(survival)
library(glmnet)
setwd("/home/ronin/Dev/notebooks/thesis_notebook/")
step2 <- read.csv("step2.csv")
# Viewing the first few rows of the dataframe
head(step2)
cox_lasso_model_with_offset <- function(df) {
# Ensure 'time' and 'event' are in the right format
y <- with(df, Surv(time, event))
# Prepare the matrix of predictors (excluding the offset)
x <- as.matrix(df[, setdiff(names(df), c("time", "event", "offset"))])
# Extract the offset
offset_values <- df$offset
# Fit Cox model with Lasso using cross-validation, including the offset
fit <- cv.glmnet(x, y, family="cox", alpha=1, offset=offset_values) # alpha=1 for Lasso
# Return the best fit and lambda value
best_lambda <- fit$lambda.min
best_fit <- glmnet(x, y, family="cox", alpha=1, lambda=best_lambda, offset=offset_values)
relibrary(survival)
library(glmnet)
setwd("/home/ronin/Dev/notebooks/thesis_notebook/")
step2 <- read.csv("step2.csv")
# Viewing the first few rows of the dataframe
head(step2)
cox_lasso_model_with_offset <- function(df) {
# Ensure 'time' and 'event' are in the right format
y <- with(df, Surv(time, event))
# Prepare the matrix of predictors (excluding the offset)
x <- as.matrix(df[, setdiff(names(df), c("time", "event", "offset"))])
# Extract the offset
offset_values <- df$offset
# Fit Cox model with Lasso using cross-validation, including the offset
fit <- cv.glmnet(x, y, family="cox", alpha=1, offset=offset_values) # alpha=1 for Lasso
return(fit)
# Return the best fit and lambda value
#best_lambda <- fit$lambda.min
#best_fit <- glmnet(x, y, family="cox", alpha=1, lambda=best_lambda, offset=offset_values)
#return(list(coef=coef(best_fit), lambda=best_lambda, fit=best_fit))
}
result <- cox_lasso_model_with_offset(step2)
result_as_matrix <- as.matrix(result$coef)
turn(list(coef=coef(best_fit), lambda=best_lambda, fit=best_fit))
}
result <- cox_lasso_model_with_offset(step2)
library(survival)
library(glmnet)
setwd("/home/ronin/Dev/notebooks/thesis_notebook/")
step2 <- read.csv("step2.csv")
# Viewing the first few rows of the dataframe
head(step2)
cox_lasso_model_with_offset <- function(df) {
# Ensure 'time' and 'event' are in the right format
y <- with(df, Surv(time, event))
# Prepare the matrix of predictors (excluding the offset)
x <- as.matrix(df[, setdiff(names(df), c("time", "event", "offset"))])
# Extract the offset
offset_values <- df$offset
# Fit Cox model with Lasso using cross-validation, including the offset
fit <- cv.glmnet(x, y, family="cox", alpha=1, offset=offset_values) # alpha=1 for Lasso
# Return the best fit and lambda value
best_lambda <- fit$lambda.min
best_fit <- glmnet(x, y, family="cox", alpha=1, lambda=best_lambda, offset=offset_values)
relibrary(survival)
library(glmnet)
setwd("/home/ronin/Dev/notebooks/thesis_notebook/")
step2 <- read.csv("step2.csv")
# Viewing the first few rows of the dataframe
head(step2)
cox_lasso_model_with_offset <- function(df) {
# Ensure 'time' and 'event' are in the right format
y <- with(df, Surv(time, event))
# Prepare the matrix of predictors (excluding the offset)
x <- as.matrix(df[, setdiff(names(df), c("time", "event", "offset"))])
# Extract the offset
offset_values <- df$offset
# Fit Cox model with Lasso using cross-validation, including the offset
fit <- cv.glmnet(x, y, family="cox", alpha=1, offset=offset_values) # alpha=1 for Lasso
return(fit)
# Return the best fit and lambda value
#best_lambda <- fit$lambda.min
#best_fit <- glmnet(x, y, family="cox", alpha=1, lambda=best_lambda, offset=offset_values)
#return(list(coef=coef(best_fit), lambda=best_lambda, fit=best_fit))
}
result <- cox_lasso_model_with_offset(step2)
result_as_matrix <- as.matrix(result$coef)
turn(list(coef=coef(best_fit), lambda=best_lambda, fit=best_fit))
}
result <- cox_lasso_model_with_offset(step2)
library(survival)
library(glmnet)
setwd("/home/ronin/Dev/notebooks/thesis_notebook/")
step2 <- read.csv("step2.csv")
# Viewing the first few rows of the dataframe
head(step2)
cox_lasso_model_with_offset <- function(df) {
# Ensure 'time' and 'event' are in the right format
y <- with(df, Surv(time, event))
# Prepare the matrix of predictors (excluding the offset)
x <- as.matrix(df[, setdiff(names(df), c("time", "event", "offset"))])
# Extract the offset
offset_values <- df$offset
# Fit Cox model with Lasso using cross-validation, including the offset
fit <- cv.glmnet(x, y, family="cox", alpha=1, offset=offset_values) # alpha=1 for Lasso
# Return the best fit and lambda value
return(fit)
#best_lambda <- fit$lambda.min
#best_fit <- glmnet(x, y, family="cox", alpha=1, lambda=best_lambda, offset=offset_values)
#return(list(coef=coef(best_fit), lambda=best_lambda, fit=best_fit))
}
result <- cox_lasso_model_with_offset(step2)
View(result)
View(result)
library(survival)
library(glmnet)
setwd("/home/ronin/Dev/notebooks/thesis_notebook/")
step2 <- read.csv("step2.csv")
# Viewing the first few rows of the dataframe
head(step2)
cox_lasso_model_with_offset <- function(df) {
# Ensure 'time' and 'event' are in the right format
y <- with(df, Surv(time, event))
# Prepare the matrix of predictors (excluding the offset)
x <- as.matrix(df[, setdiff(names(df), c("time", "event", "offset"))])
# Extract the offset
offset_values <- df$offset
# Fit Cox model with Lasso using cross-validation, including the offset
fit <- cv.glmnet(x, y, family="cox", alpha=1, offset=offset_values) # alpha=1 for Lasso
# Return the best fit and lambda value
best_lambda <- fit$lambda.min
best_fit <- glmnet(x, y, family="cox", alpha=1, lambda=best_lambda, offset=offset_values)
return(list(coef=coef(best_fit), lambda=best_lambda, fit=best_fit))
}
result <- cox_lasso_model_with_offset(step2)
result_as_matrix <- as.matrix(result$coef)
result$coef
