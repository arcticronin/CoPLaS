library(reshape2)
# confidence interval
library(dplyr)
library(tidyr)
setwd("/home/ronin/Dev/notebooks/thesis_notebook/")
data <- read.csv("DaniDatasets/preprocessed.csv")
# remove first column with patient ID
data <- data[-c(1)]
# Define the function
cox_lasso_model_with_offset <- function(df) {
# Check for necessary columns
required_cols <- c("time", "event")
if (!all(required_cols %in% names(df))) {
stop("Dataframe missing required columns: time, event")
}
# Prepare the survival object
y <- with(df, Surv(time, event))
# Prepare the matrix of predictors
predictors <- setdiff(names(df), required_cols)
x <- as.matrix(df[, predictors])
# Extract the offset
#offset_values <- df$offset
# Fit Cox model with Lasso using cross-validation
fit <- cv.glmnet(x, y, family="cox", alpha=1)
#fit <- cv.glmnet(x, y, family="cox", alpha=1, offset=offset_values)
# Best lambda and model fit
best_lambda <- fit$lambda.min
# best_fit <- glmnet(x, y, family="cox", alpha=1, lambda=best_lambda, offset=offset_values)
best_fit <- glmnet(x, y, family="cox", alpha=1, lambda=best_lambda)
# Extracting coefficients
coef_vector <- as.vector(coef(best_fit, s = best_lambda))
# handling intercept is not strictly recommended in COX, and not itnterpretable,
# so I'm leaving it out
# coef_df <- data.frame(coefficient = coef_vector, row.names = c("(Intercept)", predictors))
coef_df <- data.frame(coefficient = coef_vector, row.names = predictors)
# Return results
return(list(coef=coef_df, lambda=best_lambda, fit=best_fit))
}
model_results <- cox_lasso_model_with_offset(data)
set.seed(123) # for reproducibility
folds <- cut(seq(1, nrow(data)), breaks=5, labels=FALSE) # 5-fold CV
# Store results
cv_results <- data.frame(fold = integer(0), c_index = numeric(0))
# start crossval and store C-Index
for(i in 1:5){
# Split data into training and test sets
test_indices <- which(folds == i)
train_indices <- which(folds != i)
train_data <- data[train_indices, ]
test_data <- data[test_indices, ]
# Fit model on training data
y_train <- with(train_data, Surv(time, event))
x_train <- as.matrix(train_data[, setdiff(names(train_data), c("time", "event"))])
fit <- cv.glmnet(x_train, y_train, family="cox", alpha=1)
# Predict on test data
x_test <- as.matrix(test_data[, setdiff(names(test_data), c("time", "event"))])
predictions <- predict(fit, newx = x_test, s = "lambda.min")
# Calculate C-index for test data
#c_index <- survConcordance(Surv(test_data$time, test_data$event) ~ predictions)$concordance
c_index <- concordance(Surv(test_data$time, test_data$event) ~ predictions)$concordance
# Save results
cv_results <- rbind(cv_results, data.frame(fold = i, c_index = c_index))
}
# Calculate average C-index
mean_c_index <- mean(cv_results$c_index)
# Creare una lista per memorizzare le liste di indici
list_of_indices <- list()
set.seed(42)
folds <- cut(seq(1, nrow(data)), breaks=5, labels=FALSE) # 5-fold CV
# Store results
cv_results <- data.frame(fold = integer(0), c_index = numeric(0))
# start crossval and store C-Index
for(i in 1:5){
# Split data into training and test sets
test_indices <- which(folds == i)
train_indices <- which(folds != i)
train_data <- X[train_indices, ]
test_data <- X[test_indices, ]
# Fit model on training data
y_train = y[train_indices,]
x_train = X[train_indices,]
fit <- prioritylasso(Y = y_train,
X = x_train,
blocks = blocks,
family = "cox",
block1.penalization = TRUE,
type.measure = "deviance",
lambda.type = "lambda.min",
nfolds = 10)
# Predict on test data
x_test <- X[test_indices,]
y_test = y[test_indices,]
predictions <- predict(
object = fit,
newdata = x_test,
type = "response",
use.blocks = "all"
)
# print(predictions)
# print(y[test_indices,])
# Calculate C-index for test data
# c_index <- concordance(y_test ~ predictions)$concordance
c_index <- concordance(pred = predictions, surv = y_test)
# Save results
cv_results <- rbind(cv_results, data.frame(fold = i, c_index = c_index))
}
# survival
library(survival)
library(glmnet)
library(prioritylasso)
# plotting
library(ggplot2)
library(reshape2)
# confidence interval
library(dplyr)
library(tidyr)
setwd("Dev/notebooks/thesis_notebook/DaniDatasets/")
data = read.csv("preprocessed.csv")
indices = read.csv("indices_for_preprocessed.csv")
#preproc, remove dependent var and iupdate indices
X <- as.matrix(data[, !(names(data) %in% c("time", "event", "X"))])  # Predictor matrix
y <- Surv(data$time, data$event)  # Response variable for survival analysis
indices$index[2:nrow(indices)] <- indices$index[2:nrow(indices)] - 2
blocks = list(bp1=1:2,
bp2=3:1999,
bp3=2000:2487,
bp4=2488:3188,
bp5=3189:5464,
bp6=5465:5587,
bp7=5588:7036,
bp8=7037:8376)
# Creare una lista per memorizzare le liste di indici
list_of_indices <- list()
set.seed(42)
folds <- cut(seq(1, nrow(data)), breaks=5, labels=FALSE) # 5-fold CV
# Store results
cv_results <- data.frame(fold = integer(0), c_index = numeric(0))
# start crossval and store C-Index
for(i in 1:5){
# Split data into training and test sets
test_indices <- which(folds == i)
train_indices <- which(folds != i)
train_data <- X[train_indices, ]
test_data <- X[test_indices, ]
# Fit model on training data
y_train = y[train_indices,]
x_train = X[train_indices,]
fit <- prioritylasso(Y = y_train,
X = x_train,
blocks = blocks,
family = "cox",
block1.penalization = TRUE,
type.measure = "deviance",
lambda.type = "lambda.min",
nfolds = 10)
# Predict on test data
x_test <- X[test_indices,]
y_test = y[test_indices,]
predictions <- predict(
object = fit,
newdata = x_test,
type = "response",
use.blocks = "all"
)
# print(predictions)
# print(y[test_indices,])
# Calculate C-index for test data
# c_index <- concordance(y_test ~ predictions)$concordance
c_index <- concordance(pred = predictions, surv = y_test)
# Save results
cv_results <- rbind(cv_results, data.frame(fold = i, c_index = c_index))
}
# survival
library(survival)
library(glmnet)
library(prioritylasso)
# plotting
library(ggplot2)
library(reshape2)
# confidence interval
library(dplyr)
library(tidyr)
setwd("Dev/notebooks/thesis_notebook/DaniDatasets/")
data = read.csv("preprocessed.csv")
indices = read.csv("indices_for_preprocessed.csv")
#preproc, remove dependent var and iupdate indices
X <- as.matrix(data[, !(names(data) %in% c("time", "event", "X"))])  # Predictor matrix
y <- Surv(data$time, data$event)  # Response variable for survival analysis
indices$index[2:nrow(indices)] <- indices$index[2:nrow(indices)] - 2
blocks = list(bp1=1:2,
bp2=3:1999,
bp3=2000:2487,
bp4=2488:3188,
bp5=3189:5464,
bp6=5465:5587,
bp7=5588:7036,
bp8=7037:8376)
# Creare una lista per memorizzare le liste di indici
list_of_indices <- list()
set.seed(42)
folds <- cut(seq(1, nrow(data)), breaks=5, labels=FALSE) # 5-fold CV
# Store results
cv_results <- data.frame(fold = integer(0), c_index = numeric(0))
# start crossval and store C-Index
for(i in 1:5){
# Split data into training and test sets
test_indices <- which(folds == i)
train_indices <- which(folds != i)
train_data <- X[train_indices, ]
test_data <- X[test_indices, ]
# Fit model on training data
y_train = y[train_indices,]
x_train = X[train_indices,]
fit <- prioritylasso(Y = y_train,
X = x_train,
blocks = blocks,
family = "cox",
block1.penalization = TRUE,
type.measure = "deviance",
lambda.type = "lambda.min",
nfolds = 10)
# Predict on test data
x_test <- X[test_indices,]
y_test = y[test_indices,]
predictions <- predict(
object = fit,
newdata = x_test,
type = "response",
use.blocks = "all"
)
# print(predictions)
# print(y[test_indices,])
# Calculate C-index for test data
# c_index <- concordance(y_test ~ predictions)$concordance
c_index <- concordance(Surv(y_test$time, y_test$event) ~ predictions)
# Save results
cv_results <- rbind(cv_results, data.frame(fold = i, c_index = c_index))
}
folds <- cut(seq(1, nrow(data)), breaks=5, labels=FALSE) # 5-fold CV
# Store results
cv_results <- data.frame(fold = integer(0), c_index = numeric(0))
# start crossval and store C-Index
for(i in 1:5){
# Split data into training and test sets
test_indices <- which(folds == i)
train_indices <- which(folds != i)
train_data <- X[train_indices, ]
test_data <- X[test_indices, ]
# Fit model on training data
y_train = y[train_indices,]
x_train = X[train_indices,]
fit <- prioritylasso(Y = y_train,
X = x_train,
blocks = blocks,
family = "cox",
block1.penalization = TRUE,
type.measure = "deviance",
lambda.type = "lambda.min",
nfolds = 10)
# Predict on test data
x_test <- X[test_indices,]
y_test = y[test_indices,]
predictions <- predict(
object = fit,
newdata = x_test,
type = "response",
use.blocks = "all"
)
# print(predictions)
# print(y[test_indices,])
# Calculate C-index for test data
# c_index <- concordance(y_test ~ predictions)$concordance
c_index <- concordance(y_test ~ predictions)
# Save results
cv_results <- rbind(cv_results, data.frame(fold = i, c_index = c_index))
}
# Calculate C-index for test data
# c_index <- concordance(y_test ~ predictions)$concordance
c_index <- concordance(y_test ~ predictions)
View(c_index)
c_index[["count"]][["discordant"]]
c_index[["concordance"]]
# Calculate C-index for test data
# c_index <- concordance(y_test ~ predictions)$concordance
c_index <- concordance(y_test, predictions)
# survival
library(survival)
# Calculate C-index for test data
# c_index <- concordance(y_test ~ predictions)$concordance
c_index <- concordance(y_test, predictions)
# Calculate C-index for test data
# c_index <- concordance(y_test ~ predictions)$concordance
#c_index <- concordance(y_test, predictions)
c_index <- survConcordance(y_test ~ predictions)$concordance
# survival
library(survival)
library(glmnet)
library(prioritylasso)
# plotting
library(ggplot2)
library(reshape2)
# confidence interval
library(dplyr)
library(tidyr)
setwd("Dev/notebooks/thesis_notebook/DaniDatasets/")
data = read.csv("preprocessed.csv")
indices = read.csv("indices_for_preprocessed.csv")
#preproc, remove dependent var and iupdate indices
X <- as.matrix(data[, !(names(data) %in% c("time", "event", "X"))])  # Predictor matrix
y <- Surv(data$time, data$event)  # Response variable for survival analysis
indices$index[2:nrow(indices)] <- indices$index[2:nrow(indices)] - 2
blocks = list(bp1=1:2,
bp2=3:1999,
bp3=2000:2487,
bp4=2488:3188,
bp5=3189:5464,
bp6=5465:5587,
bp7=5588:7036,
bp8=7037:8376)
# Creare una lista per memorizzare le liste di indici
list_of_indices <- list()
set.seed(42)
folds <- cut(seq(1, nrow(data)), breaks=5, labels=FALSE) # 5-fold CV
# Store results
cv_results <- data.frame(fold = integer(0), c_index = numeric(0))
# start crossval and store C-Index
for(i in 1:5){
# Split data into training and test sets
test_indices <- which(folds == i)
train_indices <- which(folds != i)
train_data <- X[train_indices, ]
test_data <- X[test_indices, ]
# Fit model on training data
y_train = y[train_indices,]
x_train = X[train_indices,]
fit <- prioritylasso(Y = y_train,
X = x_train,
blocks = blocks,
family = "cox",
block1.penalization = TRUE,
type.measure = "deviance",
lambda.type = "lambda.min",
nfolds = 10)
# Predict on test data
x_test <- X[test_indices,]
y_test = y[test_indices,]
predictions <- predict(
object = fit,
newdata = x_test,
type = "response",
use.blocks = "all"
)
# print(predictions)
# print(y[test_indices,])
# Calculate C-index for test data
# c_index <- concordance(y_test ~ predictions)$concordance
#c_index <- concordance(y_test, predictions)
c_index <- survConcordance(y_test ~ predictions)$concordance
# Save results
cv_results <- rbind(cv_results, data.frame(fold = i, c_index = c_index))
}
# Calculate average C-index
mean_c_index <- mean(cv_results$c_index)
print(mean_c_index)
cv_results
# survival
library(survival)
library(glmnet)
library(prioritylasso)
# plotting
library(ggplot2)
library(reshape2)
# confidence interval
library(dplyr)
library(tidyr)
setwd("Dev/notebooks/thesis_notebook/DaniDatasets/")
data = read.csv("preprocessed.csv")
indices = read.csv("indices_for_preprocessed.csv")
#preproc, remove dependent var and iupdate indices
X <- as.matrix(data[, !(names(data) %in% c("time", "event", "X"))])  # Predictor matrix
y <- Surv(data$time, data$event)  # Response variable for survival analysis
indices$index[2:nrow(indices)] <- indices$index[2:nrow(indices)] - 2
blocks = list(bp1=1:2,
bp2=3:1999,
bp3=2000:2487,
bp4=2488:3188,
bp5=3189:5464,
bp6=5465:5587,
bp7=5588:7036,
bp8=7037:8376)
# Creare una lista per memorizzare le liste di indici
list_of_indices <- list()
set.seed(42)
folds <- cut(seq(1, nrow(data)), breaks=30, labels=FALSE) # 5-fold CV
# Store results
cv_results <- data.frame(fold = integer(0), c_index = numeric(0))
# start crossval and store C-Index
for(i in 1:30){
# Split data into training and test sets
test_indices <- which(folds == i)
train_indices <- which(folds != i)
train_data <- X[train_indices, ]
test_data <- X[test_indices, ]
# Fit model on training data
y_train = y[train_indices,]
x_train = X[train_indices,]
fit <- prioritylasso(Y = y_train,
X = x_train,
blocks = blocks,
family = "cox",
block1.penalization = TRUE,
type.measure = "deviance",
lambda.type = "lambda.min",
nfolds = 10)
# Predict on test data
x_test <- X[test_indices,]
y_test = y[test_indices,]
predictions <- predict(
object = fit,
newdata = x_test,
type = "response",
use.blocks = "all"
)
# print(predictions)
# print(y[test_indices,])
# Calculate C-index for test data
# c_index <- concordance(y_test ~ predictions)$concordance
#c_index <- concordance(y_test, predictions)
c_index <- survConcordance(y_test ~ predictions)$concordance
# Save results
cv_results <- rbind(cv_results, data.frame(fold = i, c_index = c_index))
}
# Calculate average C-index
mean_c_index <- mean(cv_results$c_index)
print(mean_c_index)
View(cv_results)
# Calculate average C-index
new_list <- cv_results$c_index[!sapply(cv_results$c_index, is.nan)]
mean_c_index <- mean(new_list)
print(mean_c_index)
save.image("~/Dev/notebooks/thesis_notebook/results_prior_30_folds_all.RData")
# survival
library(survival)
library(glmnet)
library(prioritylasso)
# plotting
library(ggplot2)
library(reshape2)
# confidence interval
library(dplyr)
library(tidyr)
setwd("Dev/notebooks/thesis_notebook/DaniDatasets/")
data = read.csv("preprocessed.csv")
indices = read.csv("indices_for_preprocessed.csv")
#preproc, remove dependent var and iupdate indices
X <- as.matrix(data[, !(names(data) %in% c("time", "event", "X"))])  # Predictor matrix
y <- Surv(data$time, data$event)  # Response variable for survival analysis
indices$index[2:nrow(indices)] <- indices$index[2:nrow(indices)] - 2
blocks = list(bp1=1:2,
bp2=3:1999,
bp3=2000:2487,
bp4=2488:3188,
bp5=3189:5464,
bp6=5465:5587,
bp7=5588:7036,
bp8=7037:8376)
# Creare una lista per memorizzare le liste di indici
list_of_indices <- list()
set.seed(42)
folds <- cut(seq(1, nrow(data)), breaks=5, labels=FALSE) # 5-fold CV
# Store results
cv_results <- data.frame(fold = integer(0), c_index = numeric(0))
# start crossval and store C-Index
for(i in 1:5){
# Split data into training and test sets
test_indices <- which(folds == i)
train_indices <- which(folds != i)
train_data <- X[train_indices, ]
test_data <- X[test_indices, ]
# Fit model on training data
y_train = y[train_indices,]
x_train = X[train_indices,]
fit <- prioritylasso(Y = y_train,
X = x_train,
blocks = blocks,
family = "cox",
block1.penalization = TRUE,
type.measure = "deviance",
lambda.type = "lambda.min",
nfolds = 10)
# Predict on test data
x_test <- X[test_indices,]
y_test = y[test_indices,]
predictions <- predict(
object = fit,
newdata = x_test,
type = "response",
use.blocks = "all"
)
# print(predictions)
# print(y[test_indices,])
# Calculate C-index for test data
# c_index <- concordance(y_test ~ predictions)$concordance
#c_index <- concordance(y_test, predictions)
c_index <- survConcordance(y_test ~ predictions)$concordance
# Save results
cv_results <- rbind(cv_results, data.frame(fold = i, c_index = c_index))
}
# Calculate average C-index
new_list <- cv_results$c_index[!sapply(cv_results$c_index, is.nan)]
mean_c_index <- mean(new_list)
print(mean_c_index)
